{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc2e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38b8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'fc4d70be604447858ad561a46367489b'\n",
    "ENDPOINT = 'https://face-ai-bot.cognitiveservices.azure.com/' # ****.comまで\n",
    "# FaceAPIクライアントのインスタンス作成\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e18d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pics.prcm.jp/6efa26889a740/82108524/jpeg/82108524.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abbbb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x108c90690>]\n"
     ]
    }
   ],
   "source": [
    "# URL指定によって顔検出\n",
    "detected_faces = face_client.face.detect_with_url(\n",
    "    url = url, \n",
    "    return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    ")\n",
    "print(detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8a6212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': '085ffc7d-1bdc-4740-9f09-3ef7ba58a5e3', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x108c90610>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x108c90650>}\n"
     ]
    }
   ],
   "source": [
    "print(detected_faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dfa16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'age': 24.0, 'gender': <Gender.male: 'male'>, 'smile': 0.004, 'facial_hair': None, 'glasses': <GlassesType.no_glasses: 'noGlasses'>, 'head_pose': None, 'emotion': <azure.cognitiveservices.vision.face.models._models_py3.Emotion object at 0x108c906d0>, 'hair': None, 'makeup': None, 'occlusion': None, 'accessories': None, 'blur': None, 'exposure': None, 'noise': None, 'mask': None}\n"
     ]
    }
   ],
   "source": [
    "print(detected_faces[0].face_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0653741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x108c5d6d0>]\n"
     ]
    }
   ],
   "source": [
    "# 読み込んだ画像を送信して顔検出\n",
    "with open('img/yosizawa.jpeg', 'rb') as image:\n",
    "    detected_faces_2 = face_client.face.detect_with_stream(\n",
    "        image, \n",
    "        return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    "    )\n",
    "print(detected_faces_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47294ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': '22a0d0aa-5eec-4064-b040-8f97668a7388', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x108c5d410>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x108c5d650>}\n",
      "{'additional_properties': {}, 'age': 27.0, 'gender': <Gender.male: 'male'>, 'smile': 0.855, 'facial_hair': None, 'glasses': <GlassesType.no_glasses: 'noGlasses'>, 'head_pose': None, 'emotion': <azure.cognitiveservices.vision.face.models._models_py3.Emotion object at 0x108c5d610>, 'hair': None, 'makeup': None, 'occlusion': None, 'accessories': None, 'blur': None, 'exposure': None, 'noise': None, 'mask': None}\n"
     ]
    }
   ],
   "source": [
    "print(detected_faces_2[0])\n",
    "print(detected_faces_2[0].face_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5373c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_id_1 = detected_faces[0].face_id\n",
    "face_id_2 = detected_faces_2[0].face_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57796216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': False, 'confidence': 0.46761}\n"
     ]
    }
   ],
   "source": [
    "# 2つの顔が同じ人物かどうか判定する\n",
    "verified = face_client.face.verify_face_to_face(face_id_1, face_id_2)\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7251285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person GroupのIDを指定\n",
    "person_group_id = 'moviestars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1bd9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moviestarsというグループを作成する\n",
    "face_client.person_group.update(\n",
    "    person_group_id,\n",
    "    name='Person Group for LINE Bot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c955622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Person Group for LINE Bot', 'user_data': None, 'recognition_model': None, 'person_group_id': 'moviestars'}\n"
     ]
    }
   ],
   "source": [
    "# person groupを確認\n",
    "moviestars = face_client.person_group.get(person_group_id)\n",
    "print(moviestars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f552b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 吉沢亮の名前登録\n",
    "yosizawa_name = 'Ryo Yosizawa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888a8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': None, 'user_data': None, 'person_id': '7145d158-19dc-48c0-9126-cc713d907a1e', 'persisted_face_ids': None}\n"
     ]
    }
   ],
   "source": [
    "# Personを登録\n",
    "yosizawa = face_client.person_group_person.create(\n",
    "    person_group_id = moviestars.person_group_id, # PersonGroupのIDを指定\n",
    "    name = yosizawa_name # 登録するPersonの名前を指定\n",
    ")\n",
    "print(yosizawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1aa3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': 'd9afd6bc-1d8c-4cdc-84c3-2607049eecdb', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# 画像送信でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "with open('img/yosizawa.jpeg', 'rb') as image:\n",
    "    audery_face_1 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(audery_face_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4edae695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '478a1d70-7026-4b8b-99e9-036531a6c880', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# 画像送信でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "with open('img/yosizawa2.jpeg', 'rb') as image:\n",
    "    audery_face_2 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(audery_face_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899e5e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '54c5b4dd-7082-436e-8bab-dd82f78dd95f', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# 画像送信でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "with open('img/yosizawa3.jpeg', 'rb') as image:\n",
    "    audery_face_3 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(audery_face_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6946e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '9d5f1120-034d-4076-b12a-ff40608d5e27', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# 画像送信でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "with open('img/yosizawa4.png', 'rb') as image:\n",
    "    audery_face_4 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(audery_face_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b64ce669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': None, 'user_data': None, 'person_id': '7145d158-19dc-48c0-9126-cc713d907a1e', 'persisted_face_ids': None}\n"
     ]
    }
   ],
   "source": [
    "print(yosizawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e83eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Ryo Yosizawa', 'user_data': None, 'person_id': '7145d158-19dc-48c0-9126-cc713d907a1e', 'persisted_face_ids': ['478a1d70-7026-4b8b-99e9-036531a6c880', '54c5b4dd-7082-436e-8bab-dd82f78dd95f', '9d5f1120-034d-4076-b12a-ff40608d5e27', 'd9afd6bc-1d8c-4cdc-84c3-2607049eecdb']}\n"
     ]
    }
   ],
   "source": [
    "# PersonGroupPerson get で最新のPerson情報を取得する\n",
    "yosizawa = face_client.person_group_person.get(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id\n",
    "    )\n",
    "print(yosizawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9344227",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://res.cloudinary.com/voce/image/fetch/w_750,f_auto,q_auto:eco/https://wp.i-voce.jp/wp-content/uploads/LvHjcT18_1597975878.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44924ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': 'b818d5df-956b-4a60-9b35-a606a58f35bd', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x108caa210>, 'face_landmarks': None, 'face_attributes': None}\n"
     ]
    }
   ],
   "source": [
    "# 検証用の顔検出\n",
    "detected_faces_3 = face_client.face.detect_with_url(url)\n",
    "print(detected_faces_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff7b00eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': True, 'confidence': 0.77248}\n"
     ]
    }
   ],
   "source": [
    "# personとfaceの比較\n",
    "verified = face_client.face.verify_face_to_person(\n",
    "    face_id = detected_faces_3[0].face_id,\n",
    "    person_group_id = moviestars.person_group_id,\n",
    "    person_id = yosizawa.person_id\n",
    ")\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e323b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588283a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
