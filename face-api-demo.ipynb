{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6432d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132424232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "132424232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bd4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c6b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY='fc4d70be604447858ad561a46367489b'\n",
    "ENDPOINT='https://face-ai-bot.cognitiveservices.azure.com/'\n",
    "# FaceAPIクライアントのインスタンス作成\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83697632",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pics.prcm.jp/6efa26889a740/82108524/jpeg/82108524.jpeg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c372c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x10c3ee2d0>]\n"
     ]
    }
   ],
   "source": [
    "# URL指定によって顔検出\n",
    "detected_faces = face_client.face.detect_with_url(\n",
    "    url = url, \n",
    "    return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    ")\n",
    "print(detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b76811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'age': 24.0, 'gender': <Gender.male: 'male'>, 'smile': 0.004, 'facial_hair': None, 'glasses': <GlassesType.no_glasses: 'noGlasses'>, 'head_pose': None, 'emotion': <azure.cognitiveservices.vision.face.models._models_py3.Emotion object at 0x10c3ee450>, 'hair': None, 'makeup': None, 'occlusion': None, 'accessories': None, 'blur': None, 'exposure': None, 'noise': None, 'mask': None}\n"
     ]
    }
   ],
   "source": [
    "print(detected_faces[0].face_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "257704cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x10cb8bc90>]\n"
     ]
    }
   ],
   "source": [
    "with open('img/Audrey_Hepburn_in_Charade_4.jpg', 'rb') as image:\n",
    "    detected_faces_2 = face_client.face.detect_with_stream(\n",
    "        image, \n",
    "        return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    "    )\n",
    "print(detected_faces_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afab5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': '600ffce0-307b-487b-9df7-68cc8caf54c7', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x10cb8bed0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x10cb8bad0>}\n",
      "{'additional_properties': {}, 'age': 33.0, 'gender': <Gender.female: 'female'>, 'smile': 0.0, 'facial_hair': None, 'glasses': <GlassesType.no_glasses: 'noGlasses'>, 'head_pose': None, 'emotion': <azure.cognitiveservices.vision.face.models._models_py3.Emotion object at 0x10cb8bb50>, 'hair': None, 'makeup': None, 'occlusion': None, 'accessories': None, 'blur': None, 'exposure': None, 'noise': None, 'mask': None}\n"
     ]
    }
   ],
   "source": [
    "print(detected_faces_2[0])\n",
    "print(detected_faces_2[0].face_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "859bcf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': True, 'confidence': 0.65296}\n"
     ]
    }
   ],
   "source": [
    "face_id_1 = detected_faces[0].face_id\n",
    "face_id_2 = detected_faces_2[0].face_id\n",
    "# 2つの顔が同じ人物かどうか判定する\n",
    "verified = face_client.face.verify_face_to_face(face_id_1, face_id_2)\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbf3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_group_id = 'moviestars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27eb904f",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIErrorException",
     "evalue": "(PersonGroupExists) Person group 'moviestars' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8325d51f2f67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m face_client.person_group.create(\n\u001b[1;32m      3\u001b[0m     \u001b[0mperson_group_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Person Group for LINE Bot'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/azure/cognitiveservices/vision/face/operations/_person_group_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, person_group_id, name, user_data, recognition_model, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIErrorException\u001b[0m: (PersonGroupExists) Person group 'moviestars' already exists."
     ]
    }
   ],
   "source": [
    "# moviestarsというグループを作成する\n",
    "face_client.person_group.create(\n",
    "    person_group_id,\n",
    "    name='Person Group for LINE Bot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e7fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Person Group for LINE Bot', 'user_data': None, 'recognition_model': None, 'person_group_id': 'moviestars'}\n"
     ]
    }
   ],
   "source": [
    "# person groupを確認\n",
    "moviestars = face_client.person_group.get(person_group_id)\n",
    "print(moviestars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55415d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audrey_name = 'Audrey Hepburn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94e23e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': None, 'user_data': None, 'person_id': 'fa9d9256-ed7b-4d71-abff-10c8989e0715', 'persisted_face_ids': None}\n"
     ]
    }
   ],
   "source": [
    "# Personを登録\n",
    "audrey = face_client.person_group_person.create(\n",
    "    person_group_id = moviestars.person_group_id, # PersonGroupのIDを指定\n",
    "    name = audrey_name # 登録するPersonの名前を指定\n",
    ")\n",
    "print(audrey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4345519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '0a93e620-4496-45e6-ac99-c13164f7d798', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# url指定でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "audery_face_1 = face_client.person_group_person.add_face_from_url(\n",
    "    person_group_id = moviestars.person_group_id,\n",
    "    person_id = audrey.person_id,\n",
    "    url = url\n",
    ")\n",
    "print(audery_face_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e203997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '49005a70-7f1a-4761-86a4-17ae98c04934', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "# 画像送信でオードリーヘップバーンの顔写真をPersonに紐づける\n",
    "with open('img/Audrey_Hepburn_in_Charade_4.jpg', 'rb') as image:\n",
    "    audery_face_2 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = audrey.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(audery_face_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7573988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Audrey Hepburn', 'user_data': None, 'person_id': 'fa9d9256-ed7b-4d71-abff-10c8989e0715', 'persisted_face_ids': ['0a93e620-4496-45e6-ac99-c13164f7d798', '49005a70-7f1a-4761-86a4-17ae98c04934']}\n"
     ]
    }
   ],
   "source": [
    "# PersonGroupPerson get で最新のPerson情報を取得する\n",
    "audrey = face_client.person_group_person.get(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = audrey.person_id\n",
    "    )\n",
    "print(audrey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f431256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://techpit-market-prod.s3.amazonaws.com/uploads/part_attachment/file/298/51500494-51a6-4513-bbf0-fe4f3a84e0b8.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eef3cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': 'ae676ab2-623c-4896-937b-4745079757f6', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x10cb33690>, 'face_landmarks': None, 'face_attributes': None}\n"
     ]
    }
   ],
   "source": [
    "detected_faces_3 = face_client.face.detect_with_url(url)\n",
    "print(detected_faces_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# personとfaceの比較\n",
    "verified = face_client.face.verify_face_to_person(\n",
    "    face_id = detected_faces_3[0].face_id,\n",
    "    person_group_id = moviestars.person_group_id,\n",
    "    person_id = audrey.person_id\n",
    ")\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(face_client.person_group_person.list('moviestars')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ebc747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x10d681250>]\n"
     ]
    }
   ],
   "source": [
    "# 読み込んだ画像を送信して顔検出\n",
    "with open('img/yosizawa.jpeg', 'rb') as image:\n",
    "    detected_faces_3 = face_client.face.detect_with_stream(\n",
    "        image, \n",
    "        return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    "    )\n",
    "print(detected_faces_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2061ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x10d689c10>]\n"
     ]
    }
   ],
   "source": [
    "with open('img/yosizawa2.jpeg', 'rb') as image:\n",
    "    detected_faces_4 = face_client.face.detect_with_stream(\n",
    "        image, \n",
    "        return_face_attributes = ['age','gender','smile','glasses','emotion']\n",
    "    )\n",
    "print(detected_faces_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064a8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_id_3 = detected_faces_3[0].face_id\n",
    "face_id_4 = detected_faces_4[0].face_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e29ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': True, 'confidence': 0.60348}\n"
     ]
    }
   ],
   "source": [
    "# 2つの顔が同じ人物かどうか判定する\n",
    "verified = face_client.face.verify_face_to_face(face_id_3, face_id_4)\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47108b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_group_id = 'moviestars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57dca5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIErrorException",
     "evalue": "(PersonGroupExists) Person group 'moviestars' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cf931aa49c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m face_client.person_group.create(\n\u001b[1;32m      2\u001b[0m     \u001b[0mperson_group_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Person Group for LINE Bot'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/azure/cognitiveservices/vision/face/operations/_person_group_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, person_group_id, name, user_data, recognition_model, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIErrorException\u001b[0m: (PersonGroupExists) Person group 'moviestars' already exists."
     ]
    }
   ],
   "source": [
    "face_client.person_group.create(\n",
    "    person_group_id,\n",
    "    name='Person Group for LINE Bot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5aa2c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Person Group for LINE Bot', 'user_data': None, 'recognition_model': None, 'person_group_id': 'moviestars'}\n"
     ]
    }
   ],
   "source": [
    "moviestars = face_client.person_group.get(person_group_id)\n",
    "print(moviestars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cad0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yosizawa_name = 'Ryo Yosizawa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88aacca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': None, 'user_data': None, 'person_id': 'f02ce9a9-ff0c-4a72-a71e-eb0fe8716b37', 'persisted_face_ids': None}\n"
     ]
    }
   ],
   "source": [
    "yosizawa = face_client.person_group_person.create(\n",
    "    person_group_id = moviestars.person_group_id, # PersonGroupのIDを指定\n",
    "    name = yosizawa_name # 登録するPersonの名前を指定\n",
    ")\n",
    "print(yosizawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0c4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '8b25c8d3-a70c-4059-b562-9c5ec88f08a3', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "with open('img/yosizawa.jpeg', 'rb') as image:\n",
    "    yosizawa_face_1 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(yosizawa_face_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d951f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '5580917e-2fec-46aa-8ef0-ce3896f312e9', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "with open('img/yosizawa2.jpeg', 'rb') as image:\n",
    "    yosizawa_face_2 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(yosizawa_face_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377e9cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'persisted_face_id': '8eddd54d-d0b0-471f-a0a1-093b3396ad03', 'user_data': None}\n"
     ]
    }
   ],
   "source": [
    "with open('img/yosizawa3.jpeg', 'rb') as image:\n",
    "    yosizawa_face_3 = face_client.person_group_person.add_face_from_stream(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id,\n",
    "        image = image\n",
    "    )\n",
    "print(yosizawa_face_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f5933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Ryo Yosizawa', 'user_data': None, 'person_id': 'f02ce9a9-ff0c-4a72-a71e-eb0fe8716b37', 'persisted_face_ids': ['5580917e-2fec-46aa-8ef0-ce3896f312e9', '8b25c8d3-a70c-4059-b562-9c5ec88f08a3', '8eddd54d-d0b0-471f-a0a1-093b3396ad03']}\n"
     ]
    }
   ],
   "source": [
    "# PersonGroupPerson get で最新のPerson情報を取得する\n",
    "yosizawa = face_client.person_group_person.get(\n",
    "        person_group_id = moviestars.person_group_id,\n",
    "        person_id = yosizawa.person_id\n",
    "    )\n",
    "print(yosizawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08804fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Ryo Yosizawa', 'user_data': None, 'person_id': '5cc0f9c9-31f1-49a7-b794-aeaa4f723ed9', 'persisted_face_ids': ['0f3fb2b2-8fb1-42c0-9c15-669889e98573', '26e6dc0d-67a8-445b-a2e4-dc7e8523e99b', '742afa3d-70e2-4aa2-ba58-d2642d3cc743', '9ffbc535-e22c-49cd-8400-16b250edfb6e']}\n"
     ]
    }
   ],
   "source": [
    "print(face_client.person_group_person.list('moviestars')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85ebb783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'name': 'Audrey Hepburn', 'user_data': None, 'person_id': 'fa9d9256-ed7b-4d71-abff-10c8989e0715', 'persisted_face_ids': ['0a93e620-4496-45e6-ac99-c13164f7d798', '49005a70-7f1a-4761-86a4-17ae98c04934']}\n"
     ]
    }
   ],
   "source": [
    "print(face_client.person_group_person.list('moviestars')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda025b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'face_id': '652f460b-f53c-4e71-b8f2-e0e4dafa76a9', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x10c4a1910>, 'face_landmarks': None, 'face_attributes': None}\n"
     ]
    }
   ],
   "source": [
    "detected_faces_4 = face_client.face.detect_with_url(url)\n",
    "print(detected_faces_4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91ea938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_identical': True, 'confidence': 0.55983}\n"
     ]
    }
   ],
   "source": [
    "verified = face_client.face.verify_face_to_person(\n",
    "    face_id = detected_faces_4[0].face_id,\n",
    "    person_group_id = moviestars.person_group_id,\n",
    "    person_id = yosizawa.person_id\n",
    ")\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc17375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
